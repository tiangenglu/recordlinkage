{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "892b2d01",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Similar-Texts-Recommendation-Program\" data-toc-modified-id=\"Similar-Texts-Recommendation-Program-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Similar Texts Recommendation Program</a></span></li><li><span><a href=\"#Data\" data-toc-modified-id=\"Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data</a></span></li><li><span><a href=\"#Text-Processing\" data-toc-modified-id=\"Text-Processing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Text Processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#What-does-text-processing-do?\" data-toc-modified-id=\"What-does-text-processing-do?-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>What does text processing do?</a></span></li><li><span><a href=\"#Apply-text-processing-to-all-text\" data-toc-modified-id=\"Apply-text-processing-to-all-text-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Apply text processing to all text</a></span></li></ul></li><li><span><a href=\"#TF-IDF-(Term-Frequency---Inverse-Document-Frequency)\" data-toc-modified-id=\"TF-IDF-(Term-Frequency---Inverse-Document-Frequency)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>TF-IDF (Term Frequency - Inverse Document Frequency)</a></span></li><li><span><a href=\"#Cosine-Similarity\" data-toc-modified-id=\"Cosine-Similarity-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Cosine-Similarity</a></span></li><li><span><a href=\"#Why-are-texts-similar?—Common-features\" data-toc-modified-id=\"Why-are-texts-similar?—Common-features-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Why are texts similar?—Common features</a></span></li><li><span><a href=\"#Output\" data-toc-modified-id=\"Output-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Output</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09292d39",
   "metadata": {},
   "source": [
    "# Similar Texts Recommendation Program\n",
    "\n",
    "1. This program finds top n most similar texts (article titles + abstracts) for a given text using term frequency inverse document frequency and cosine similarity.\n",
    "2. This can be applied to literature review and document classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77b294e",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "bb94531d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This jupyter notebook was created on  05/27/2023, Saturday, 02:38 AM\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time as tm\n",
    "start_time = tm.strftime(\"%m/%d/%Y, %A, %H:%M %p\")\n",
    "print(\"This jupyter notebook was created on \", str(start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "13a9bd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"mig_analysis.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "4d0de247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Author Full Names', 'Source Title', 'Times Cited, WoS Core',\n",
       "       'Publication Year', 'WoS Categories', 'id', 'id2', 'keywords', 'decade',\n",
       "       'alltext', 'token'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which are the variables?\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d761528a",
   "metadata": {},
   "source": [
    "# Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "07ba9307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the article title and abstract\n",
    "# no need to fill NA with ' ' because I really need the full text\n",
    "df['alltext'] = df['Article Title'] + ' ' + df['Abstract']\n",
    "# drop the columns\n",
    "df = df.drop(['Article Title', 'Abstract'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "dcbbea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with any NAs\n",
    "df = df.dropna(how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "8adf1358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2439\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author Full Names</th>\n",
       "      <th>Source Title</th>\n",
       "      <th>Times Cited, WoS Core</th>\n",
       "      <th>Publication Year</th>\n",
       "      <th>WoS Categories</th>\n",
       "      <th>id</th>\n",
       "      <th>id2</th>\n",
       "      <th>keywords</th>\n",
       "      <th>decade</th>\n",
       "      <th>alltext</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>Ly Thi Tran; Tan, George; Bui, Huyen; Rahimi, ...</td>\n",
       "      <td>POPULATION SPACE AND PLACE</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Demography; Geography</td>\n",
       "      <td>23_50</td>\n",
       "      <td>2616</td>\n",
       "      <td>EMPLOYMENT OUTCOMES; GRADUATE EMPLOYABILITY; H...</td>\n",
       "      <td>t20</td>\n",
       "      <td>international graduates on temporary post grad...</td>\n",
       "      <td>intern graduat temporari post graduat visa aus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>Mabi, Millicent N.; O'Brien, Heather L.; Natha...</td>\n",
       "      <td>JOURNAL OF DOCUMENTATION</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>Computer Science, Information Systems; Informa...</td>\n",
       "      <td>23_51</td>\n",
       "      <td>2617</td>\n",
       "      <td>INFORMATION POVERTY; AFRICAN IMMIGRANTS; INFOR...</td>\n",
       "      <td>t20</td>\n",
       "      <td>questioning the role of information poverty in...</td>\n",
       "      <td>question role inform poverti immigr employ acq...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Author Full Names  \\\n",
       "2615  Ly Thi Tran; Tan, George; Bui, Huyen; Rahimi, ...   \n",
       "2616  Mabi, Millicent N.; O'Brien, Heather L.; Natha...   \n",
       "\n",
       "                    Source Title  Times Cited, WoS Core  Publication Year  \\\n",
       "2615  POPULATION SPACE AND PLACE                      0              2023   \n",
       "2616    JOURNAL OF DOCUMENTATION                      1              2023   \n",
       "\n",
       "                                         WoS Categories     id   id2  \\\n",
       "2615                              Demography; Geography  23_50  2616   \n",
       "2616  Computer Science, Information Systems; Informa...  23_51  2617   \n",
       "\n",
       "                                               keywords decade  \\\n",
       "2615  EMPLOYMENT OUTCOMES; GRADUATE EMPLOYABILITY; H...    t20   \n",
       "2616  INFORMATION POVERTY; AFRICAN IMMIGRANTS; INFOR...    t20   \n",
       "\n",
       "                                                alltext  \\\n",
       "2615  international graduates on temporary post grad...   \n",
       "2616  questioning the role of information poverty in...   \n",
       "\n",
       "                                                  token  \n",
       "2615  intern graduat temporari post graduat visa aus...  \n",
       "2616  question role inform poverti immigr employ acq...  "
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remaining observations\n",
    "print(df.shape[0])\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "2370ea75",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# to surpress warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "# lemmatize: to the base form of a word\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# keep the root of a word\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "lm = WordNetLemmatizer()\n",
    "# abstracts also available in Spanish and/or German sometimes\n",
    "stopwords = set(stopwords.words(['english','spanish','german']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310c1e6f",
   "metadata": {},
   "source": [
    "## What does text processing do?\n",
    "\n",
    "- A brief demostration of what each step does\n",
    "- Comparing output under different configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "c8fa0f10",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. STEM & LEMMATIZE, then TOKENIZE:\n",
      " ['thi', 'paper', 'take', 'a', 'preliminari', 'look', 'at', 'a', 'disaggreg', 'data', 'sourc', 'not', 'previous', 'use', 'in', 'the', 'analysi', 'of', 'northern-ireland', 'migrat', 'pattern', '.'] \n",
      "Puntuations and stopwords are here.\n",
      "\n",
      "2. STEM & LEMMATIZE, TOKENIZE, and LETTERS only:\n",
      " ['thi', 'paper', 'take', 'a', 'preliminari', 'look', 'at', 'a', 'disaggreg', 'data', 'sourc', 'not', 'previous', 'use', 'in', 'the', 'analysi', 'of', 'migrat', 'pattern'] \n",
      "Stopwords are still here.\n",
      "\n",
      "3. STEM & LEMMATIZE,TOKENIZE, LETTERS only, and NO STOPWRODS:\n",
      " ['thi', 'paper', 'take', 'preliminari', 'look', 'disaggreg', 'data', 'sourc', 'previous', 'use', 'analysi', 'migrat', 'pattern'] \n",
      "Both punctuations and stopwords are gone.\n"
     ]
    }
   ],
   "source": [
    "# replace hyphen '-' with ' '\n",
    "body = 'This paper takes a preliminary look at a disaggregate data source not previously used in the analysis of Northern-Ireland migration patterns. '\n",
    "# Generator expression must be parenthesized with []\n",
    "print(\"1. STEM & LEMMATIZE, then TOKENIZE:\\n\"\\\n",
    "      ,[stemmer.stem(lm.lemmatize(w)) for w in word_tokenize(body)],\"\\nPuntuations and stopwords are here.\\n\")\n",
    "print(\"2. STEM & LEMMATIZE, TOKENIZE, and LETTERS only:\\n\"\\\n",
    "      ,[stemmer.stem(lm.lemmatize(w)) for w in word_tokenize(body) if w.isalpha()],'\\nStopwords are still here.\\n')\n",
    "print(\"3. STEM & LEMMATIZE,TOKENIZE, LETTERS only, and NO STOPWRODS:\\n\"\\\n",
    "      ,[stemmer.stem(lm.lemmatize(w)) for w in word_tokenize(body) if (w.isalpha() and w not in stopwords)],\"\\nBoth punctuations and stopwords are gone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126fb8e2",
   "metadata": {},
   "source": [
    "## Apply text processing to all text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "72a9a8de",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# set to lowercase\n",
    "df['alltext'] = df['alltext'].str.lower()\n",
    "\n",
    "# replace hyphen '-' with ' '. w/o this step, words w/ '-' are removed at w.isalpha() step\n",
    "df['alltext'] = df['alltext'].str.replace('-',' ')\n",
    "\n",
    "# initiate a blank list, fill it later by appending the individual results\n",
    "tokens = []\n",
    "\n",
    "# loop for each observation/row in the alltext column/variable\n",
    "for row in df['alltext']:\n",
    "    # use [] to wrap what I'd like to do with the object\n",
    "    # here, the object is the single words(as 'w') in each row\n",
    "    my_token = [stemmer.stem(lm.lemmatize(w)) for w in word_tokenize(row)\\\n",
    "               if (w.isalpha() and w not in stopwords)]\n",
    "    # add individual tokenized words by joining them together as one text body\n",
    "    tokens.append(' '.join(map(str, my_token)))\n",
    "df['token'] = tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51235b61",
   "metadata": {},
   "source": [
    "# TF-IDF (Term Frequency - Inverse Document Frequency)\n",
    "\n",
    "$$w_{i,j} = tf_{i,j} \\times log\\frac{N}{df_{i}}$$\n",
    "\n",
    "where\n",
    "\n",
    "- $tf_{i,j} = $ the number of occurrences of $i$ and $j$\n",
    "- $df_{i} = $ the number of documents containing $i$\n",
    "- $N = $ total number of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "55fb5160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words = 'english', max_df = 0.5, min_df = 3)\n",
    "corpus = tfidf_vectorizer.fit_transform(df['token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "9f6e817c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508669f3",
   "metadata": {},
   "source": [
    "At this step, the `['alltext']` column has been fitted to a `corpus`. Next, transform the `corpus` to a dataframe, with the selected features(tokenized words) as column names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "c0d373ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the type/property of the vectorized features? -- Numpy array.\n",
    "print(type(tfidf_vectorizer.get_feature_names_out()))\n",
    "# Randomly check whether a stopword exists in the features:\n",
    "np.where(tfidf_vectorizer.get_feature_names_out() == \"and\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "2ec2ddef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix_df = pd.DataFrame(corpus.toarray(),\\\n",
    "                              columns = tfidf_vectorizer.get_feature_names_out(),\\\n",
    "                              index = df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "e33176c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absenc</th>\n",
       "      <th>absent</th>\n",
       "      <th>absolut</th>\n",
       "      <th>absorb</th>\n",
       "      <th>abstract</th>\n",
       "      <th>abu</th>\n",
       "      <th>...</th>\n",
       "      <th>yield</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>yugoslavia</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zero</th>\n",
       "      <th>zimbabw</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2439 rows × 3754 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abandon  abil   abl  abroad  absenc  absent  absolut  absorb  abstract  \\\n",
       "18        0.0  0.00  0.00     0.0     0.0     0.0      0.0     0.0       0.0   \n",
       "20        0.0  0.00  0.00     0.0     0.0     0.0      0.0     0.0       0.0   \n",
       "23        0.0  0.00  0.00     0.0     0.0     0.0      0.0     0.0       0.0   \n",
       "24        0.0  0.00  0.00     0.0     0.0     0.0      0.0     0.0       0.0   \n",
       "26        0.0  0.00  0.00     0.0     0.0     0.0      0.0     0.0       0.0   \n",
       "...       ...   ...   ...     ...     ...     ...      ...     ...       ...   \n",
       "2612      0.0  0.00  0.07     0.0     0.0     0.0      0.0     0.0       0.0   \n",
       "2613      0.0  0.00  0.00     0.0     0.0     0.0      0.0     0.0       0.0   \n",
       "2614      0.0  0.00  0.00     0.0     0.0     0.0      0.0     0.0       0.0   \n",
       "2615      0.0  0.00  0.00     0.0     0.0     0.0      0.0     0.0       0.0   \n",
       "2616      0.0  0.05  0.00     0.0     0.0     0.0      0.0     0.0       0.0   \n",
       "\n",
       "      abu  ...  yield  york  young  younger  youth  yugoslavia  zealand  zero  \\\n",
       "18    0.0  ...    0.0   0.0    0.0     0.00    0.0         0.0      0.0   0.0   \n",
       "20    0.0  ...    0.0   0.0    0.0     0.00    0.0         0.0      0.0   0.0   \n",
       "23    0.0  ...    0.0   0.0    0.0     0.00    0.0         0.0      0.0   0.0   \n",
       "24    0.0  ...    0.0   0.0    0.0     0.00    0.0         0.0      0.0   0.0   \n",
       "26    0.0  ...    0.0   0.0    0.0     0.00    0.0         0.0      0.0   0.0   \n",
       "...   ...  ...    ...   ...    ...      ...    ...         ...      ...   ...   \n",
       "2612  0.0  ...    0.0   0.0    0.0     0.00    0.0         0.0      0.0   0.0   \n",
       "2613  0.0  ...    0.0   0.0    0.0     0.09    0.0         0.0      0.0   0.0   \n",
       "2614  0.0  ...    0.0   0.0    0.0     0.00    0.0         0.0      0.0   0.0   \n",
       "2615  0.0  ...    0.0   0.0    0.0     0.00    0.0         0.0      0.0   0.0   \n",
       "2616  0.0  ...    0.0   0.0    0.0     0.00    0.0         0.0      0.0   0.0   \n",
       "\n",
       "      zimbabw  zone  \n",
       "18        0.0  0.00  \n",
       "20        0.0  0.00  \n",
       "23        0.0  0.00  \n",
       "24        0.0  0.00  \n",
       "26        0.0  0.00  \n",
       "...       ...   ...  \n",
       "2612      0.0  0.09  \n",
       "2613      0.0  0.00  \n",
       "2614      0.0  0.00  \n",
       "2615      0.0  0.00  \n",
       "2616      0.0  0.00  \n",
       "\n",
       "[2439 rows x 3754 columns]"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(tfidf_matrix_df,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3f64d4",
   "metadata": {},
   "source": [
    "# Cosine-Similarity\n",
    "\n",
    "$$similarity(A,B) = cos(\\theta) = \\frac{A \\times B}{\\|A\\| \\|B\\|} = \\frac{\\sum\\limits_{i = 1}^{n} A_{i} B_{i}}{\\sqrt{\\sum\\limits_{i = 1}^{n} A^{2}_{i}} \\sqrt{\\sum\\limits_{i = 1}^{n} B^{2}_{i}}}$$\n",
    "\n",
    "where\n",
    "\n",
    "- $\\theta$ is the angle between the vectors,\n",
    "- $A \\times B$ is dot product between $A$ and $B$ and calculated as $A \\times B = A^{T}B = \\Sigma^{n}_{i = 1} A_{i}B_{i} = A_{1}B_{1} + A_{2}B_{2} + ... + A_{n}B_{n}$\n",
    "- $\\|A\\|$ represents the $L_{2}$ norm or magnitude of the vector which is calculated as $\\|A\\| = \\sqrt{A^{2}_{1} + A^{2}_{2} + ... + A^{2}_{n}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "ad1adbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_sim = pd.DataFrame(cosine_similarity(tfidf_matrix_df,\\\n",
    "                                            dense_output = True),\\\n",
    "                                           columns = df.index,\\\n",
    "                                           index = df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "81da1be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  18,   20,   23,   24,   26,   28,   29,   31,   34,   36,\n",
       "            ...\n",
       "            2607, 2608, 2609, 2610, 2611, 2612, 2613, 2614, 2615, 2616],\n",
       "           dtype='int64', length=2439)"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "f45cea20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.92 s, sys: 60.7 ms, total: 3.98 s\n",
      "Wall time: 4.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(cosine_sim)):\n",
    "    top_score = cosine_sim.iloc[i].sort_values(ascending = False)[1:6]\n",
    "    # be careful with the following, make sure to use the index to index the df\n",
    "    # also, select the \"useful\" columns from the df to keep in the result\n",
    "    output = df.loc[cosine_sim.iloc[i].sort_values(ascending = False).index[1:6],\\\n",
    "                    ['id','id2','WoS Categories','alltext']]\n",
    "    output = output.reset_index(drop = True)\n",
    "    # put all results together: copy the result from the first iteration\n",
    "    if i == 0:\n",
    "        all_outputs = output.copy(deep = True)\n",
    "        all_scores = top_score.copy(deep = True)\n",
    "    # after the first iteration, concatenate the following results\n",
    "    else:\n",
    "        all_outputs = pd.concat([all_outputs, output])\n",
    "        all_scores = pd.concat([all_scores, top_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "5a7142f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = pd.DataFrame(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "06e1a6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12195\n",
      "   cosine_similarity\n",
      "0           0.318249\n",
      "1           0.311735\n",
      "2           0.298912\n",
      "3           0.294885\n",
      "4           0.271116\n"
     ]
    }
   ],
   "source": [
    "all_scores = all_scores.rename(columns={0:\"cosine_similarity\"}).reset_index(drop = True)\n",
    "print(all_scores.shape[0])\n",
    "print(all_scores.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "8150d7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id2\n",
       "0         19\n",
       "1         19\n",
       "2         19\n",
       "3         19\n",
       "4         19"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a query id data frame that repeats n time--consistent with the top n matches\n",
    "match_id = pd.DataFrame(np.repeat(df[['id2']].values, 5, axis = 0)).rename(columns={0:'query_id2'})\n",
    "match_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "533cb14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = all_scores.reset_index(drop=True)\n",
    "# reset index\n",
    "match_id = match_id.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "c3c36e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# match python's zero indexing\n",
    "all_outputs['rank'] = all_outputs.index+1\n",
    "# reset index\n",
    "all_outputs = all_outputs.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "dba4c8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data frames to be concatenated must have consistent indeces\n",
    "matches_df = pd.concat([match_id, all_scores, all_outputs],axis=1).\\\n",
    "rename(columns={'id':'match_id','id2':'match_id2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "ef676b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the final results with the query ids\n",
    "# rename the columns to make them more explanatory \n",
    "final_output = df[['alltext','id','id2']]\\\n",
    ".merge(matches_df, left_on='id2', right_on='query_id2', how = 'inner')\\\n",
    ".rename(columns={'alltext_x':'query_text', 'id':'query_id', 'alltext_y':'match_text'})\\\n",
    ".drop(['id2','query_id2','WoS Categories'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "7e74544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the upper and lower cut-off of cosine_similarity\n",
    "final_output = \\\n",
    "final_output[(final_output['cosine_similarity'] < 0.99) & (final_output['cosine_similarity'] > 0.3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "d737df1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6047.000000\n",
       "mean        0.382366\n",
       "std         0.075261\n",
       "min         0.300002\n",
       "25%         0.327077\n",
       "50%         0.360428\n",
       "75%         0.416307\n",
       "max         0.795589\n",
       "Name: cosine_similarity, dtype: float64"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distribution of cosine_similarity scores\n",
    "final_output['cosine_similarity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "282d807c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6047"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after filtering the cosine similarity scores, the remaining rows\n",
    "final_output.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "7d6367a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1854\n",
       "2    1412\n",
       "3    1128\n",
       "4     917\n",
       "5     736\n",
       "Name: rank, dtype: int64"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the distribution of ranked matches\n",
    "final_output['rank'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf6fb4c",
   "metadata": {},
   "source": [
    "# Why are texts similar?—Common features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "ff1b0ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "allow       0.064269\n",
       "analysi     0.080951\n",
       "benefici    0.088011\n",
       "brain       0.123310\n",
       "capit       0.045787\n",
       "              ...   \n",
       "unemploy    0.065561\n",
       "urban       0.119121\n",
       "wage        0.048593\n",
       "welfar      0.063713\n",
       "worker      0.033935\n",
       "Name: 18, Length: 67, dtype: float64"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show non-zero features and their scores of each row\n",
    "tfidf_matrix_df.iloc[0][tfidf_matrix_df.iloc[0]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "0494a8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['allow', 'analysi', 'benefici', 'brain', 'capit', 'caput', 'caus',\n",
       "       'character', 'condit', 'consequ', 'construct', 'countri', 'cours',\n",
       "       'develop', 'discov', 'drain', 'effect', 'emigr', 'examin', 'exchang',\n",
       "       'export', 'fall', 'foreign', 'gain', 'growth', 'harri', 'home',\n",
       "       'impact', 'incom', 'labor', 'laid', 'ldc', 'le', 'long', 'lose', 'loss',\n",
       "       'model', 'order', 'paper', 'period', 'phenomenon', 'possibl',\n",
       "       'profession', 'promot', 'purpos', 'rate', 'real', 'receiv', 'remitt',\n",
       "       'return', 'rise', 'run', 'rural', 'second', 'sector', 'short', 'social',\n",
       "       'theoret', 'todaro', 'type', 'ultim', 'unambigu', 'unemploy', 'urban',\n",
       "       'wage', 'welfar', 'worker'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# non-zero features as column names from the tfidf_matrix\n",
    "tfidf_matrix_df.columns[tfidf_matrix_df.iloc[0]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "5006e475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['growth',\n",
       " 'emigr',\n",
       " 'receiv',\n",
       " 'labor',\n",
       " 'develop',\n",
       " 'consequ',\n",
       " 'countri',\n",
       " 'exchang']"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# common features between two articles\n",
    "list(set(tfidf_matrix_df.columns[tfidf_matrix_df.iloc[0]>0])\\\n",
    "     & set(tfidf_matrix_df.columns[tfidf_matrix_df.iloc[1]>0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "5138bf4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.indexes.base.Index"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tfidf_matrix_df.columns[tfidf_matrix_df.iloc[0]>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "51703f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm the rows in the original df equals to the rows in the tfidf_matrix\n",
    "df.shape[0] == tfidf_matrix_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "31a262f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absenc</th>\n",
       "      <th>absent</th>\n",
       "      <th>absolut</th>\n",
       "      <th>absorb</th>\n",
       "      <th>abstract</th>\n",
       "      <th>abu</th>\n",
       "      <th>...</th>\n",
       "      <th>yield</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>yugoslavia</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zero</th>\n",
       "      <th>zimbabw</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91_3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92_1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92_4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92_5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92_7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3754 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abandon  abil  abl  abroad  absenc  absent  absolut  absorb  abstract  \\\n",
       "id                                                                            \n",
       "91_3      0.0   0.0  0.0     0.0     0.0     0.0      0.0     0.0       0.0   \n",
       "92_1      0.0   0.0  0.0     0.0     0.0     0.0      0.0     0.0       0.0   \n",
       "92_4      0.0   0.0  0.0     0.0     0.0     0.0      0.0     0.0       0.0   \n",
       "92_5      0.0   0.0  0.0     0.0     0.0     0.0      0.0     0.0       0.0   \n",
       "92_7      0.0   0.0  0.0     0.0     0.0     0.0      0.0     0.0       0.0   \n",
       "\n",
       "      abu  ...  yield  york  young  younger  youth  yugoslavia  zealand  zero  \\\n",
       "id         ...                                                                  \n",
       "91_3  0.0  ...    0.0   0.0    0.0      0.0    0.0         0.0      0.0   0.0   \n",
       "92_1  0.0  ...    0.0   0.0    0.0      0.0    0.0         0.0      0.0   0.0   \n",
       "92_4  0.0  ...    0.0   0.0    0.0      0.0    0.0         0.0      0.0   0.0   \n",
       "92_5  0.0  ...    0.0   0.0    0.0      0.0    0.0         0.0      0.0   0.0   \n",
       "92_7  0.0  ...    0.0   0.0    0.0      0.0    0.0         0.0      0.0   0.0   \n",
       "\n",
       "      zimbabw  zone  \n",
       "id                   \n",
       "91_3      0.0   0.0  \n",
       "92_1      0.0   0.0  \n",
       "92_4      0.0   0.0  \n",
       "92_5      0.0   0.0  \n",
       "92_7      0.0   0.0  \n",
       "\n",
       "[5 rows x 3754 columns]"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It is time to re-index, using the id column to be the new index.\n",
    "# This helps adding more information to the final results\n",
    "tfidf_matrix_df.index = df['id']\n",
    "tfidf_matrix_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "b23bffe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91_3\n",
      "13_56\n"
     ]
    }
   ],
   "source": [
    "range(len(final_output))\n",
    "print(final_output['query_id'].iloc[0])\n",
    "print(final_output['match_id'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "837f95a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate an empty list\n",
    "common_feature = []\n",
    "# find the features in both the query and match ids, then get the common features\n",
    "for i in range(len(final_output)):\n",
    "    feature = list(set(tfidf_matrix_df.columns[tfidf_matrix_df.loc[final_output['query_id'].iloc[i]]>0])\\\n",
    "                   & set(tfidf_matrix_df.columns[tfidf_matrix_df.loc[final_output['match_id'].iloc[i]]>0]))\n",
    "    common_feature.append(', '.join(map(str,feature)))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "98d2313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the common feature to the final output data frame\n",
    "final_output['common_feature'] = common_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "b7a13251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_text</th>\n",
       "      <th>match_id</th>\n",
       "      <th>match_text</th>\n",
       "      <th>common_feature</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91_3</td>\n",
       "      <td>a theoretical analysis of the beneficial effec...</td>\n",
       "      <td>13_56</td>\n",
       "      <td>what circumstances lead a government to promot...</td>\n",
       "      <td>worker, emigr, caput, fall, le, brain, drain, ...</td>\n",
       "      <td>0.318249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91_3</td>\n",
       "      <td>a theoretical analysis of the beneficial effec...</td>\n",
       "      <td>11_67</td>\n",
       "      <td>the brain drain and the world distribution of ...</td>\n",
       "      <td>emigr, analysi, short, possibl, effect, long, ...</td>\n",
       "      <td>0.311735</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>92_4</td>\n",
       "      <td>factor mobility, trade and welfare   a north s...</td>\n",
       "      <td>17_139</td>\n",
       "      <td>north south migrations and the asymmetric expu...</td>\n",
       "      <td>popul, capit, develop, south, mobil, affect, n...</td>\n",
       "      <td>0.487309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>92_4</td>\n",
       "      <td>factor mobility, trade and welfare   a north s...</td>\n",
       "      <td>19_175</td>\n",
       "      <td>a tale of two countries: directed technical ch...</td>\n",
       "      <td>unskil, posit, substitut, labor, trade, south,...</td>\n",
       "      <td>0.351653</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>92_4</td>\n",
       "      <td>factor mobility, trade and welfare   a north s...</td>\n",
       "      <td>14_72</td>\n",
       "      <td>trade, capital adjustment and the migration of...</td>\n",
       "      <td>unskil, sector, capit, labor, develop, trade, ...</td>\n",
       "      <td>0.341164</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                                         query_text match_id  \\\n",
       "0      91_3  a theoretical analysis of the beneficial effec...    13_56   \n",
       "1      91_3  a theoretical analysis of the beneficial effec...    11_67   \n",
       "10     92_4  factor mobility, trade and welfare   a north s...   17_139   \n",
       "11     92_4  factor mobility, trade and welfare   a north s...   19_175   \n",
       "12     92_4  factor mobility, trade and welfare   a north s...    14_72   \n",
       "\n",
       "                                           match_text  \\\n",
       "0   what circumstances lead a government to promot...   \n",
       "1   the brain drain and the world distribution of ...   \n",
       "10  north south migrations and the asymmetric expu...   \n",
       "11  a tale of two countries: directed technical ch...   \n",
       "12  trade, capital adjustment and the migration of...   \n",
       "\n",
       "                                       common_feature  cosine_similarity  rank  \n",
       "0   worker, emigr, caput, fall, le, brain, drain, ...           0.318249     1  \n",
       "1   emigr, analysi, short, possibl, effect, long, ...           0.311735     2  \n",
       "10  popul, capit, develop, south, mobil, affect, n...           0.487309     1  \n",
       "11  unskil, posit, substitut, labor, trade, south,...           0.351653     2  \n",
       "12  unskil, sector, capit, labor, develop, trade, ...           0.341164     3  "
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the final results\n",
    "final_output[['query_id','query_text','match_id','match_text','common_feature','cosine_similarity','rank']]\\\n",
    ".head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "5ccc461d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     worker, emigr, caput, fall, le, brain, drain, ...\n",
       "1     emigr, analysi, short, possibl, effect, long, ...\n",
       "10    popul, capit, develop, south, mobil, affect, n...\n",
       "11    unskil, posit, substitut, labor, trade, south,...\n",
       "12    unskil, sector, capit, labor, develop, trade, ...\n",
       "Name: common_feature, dtype: object"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output['common_feature'][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3041642d",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "ae52327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output.to_csv('article_similarity.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python395jvsc74a57bd07812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "609px",
    "left": "384px",
    "top": "124.141px",
    "width": "210px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
